\clearemptydoublepage
\phantomsection
\addcontentsline{toc}{chapter}{Abstract}

\vspace*{1cm}
\begin{center}
{\Large \bf Abstract}
\end{center}
\vspace{1cm}

Localization is an essential ability for mobile robots, and visual localization has shown much potential as a cost effective solution.  However, even state of the art solutions do not provide the robustness required for real-world-robotics applications. This thesis proposes an approach for visual localization by combining multiple camera types.  The approach utilises complimentary properties of the camera types in order to improve overall accuracy and robustness. A fusion of stereo and omnidirectional cameras is demonstrated by incorporating loop closures as detected by the omnidirectional camera into a SLAM graph of an existing stereo SLAM system.  Two algorithms that combine stereo and omnidirectional camera data to solve the scale problem associated with pose estimation of mono imagery are presented and compared.  Furthermore, an extrinsic calibration method for the intended camera setup is outlined.  This allows for a high accuracy transformation between stereo and omnidirectional cameras to obtain the best possible results of the camera fusion. An extensive evaluation of the entire system is performed, comparing against performance achieved with a stereo only SLAM system, and found up to 82\% improvement in trajectory accuracy.

