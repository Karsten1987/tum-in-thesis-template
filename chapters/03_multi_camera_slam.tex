\chapter{Multiple Cameras for SLAM}
\label{chapter:MultiCamSLAM}

\section{Motivation}

There has been significant research in the area of visual SLAM for stereo cameras (cite, cite, cite).  Stereo SLAM has been shown to work very well, however there are a few intrinsic drawbacks of using projective cameras, mainly, the limited field of view.  A larger field of view allows features to be tracked for longer, which in turn provides more accurate point triangulation.  In addition to better triangulation, a larger field of view allows greater overlap of frames, particularly with rotational motion.  This results in pose estimation that is more robust and easier localization against an existing map. %occlusions?
%TODO:: citation

Using an omnidirectional lense allows a 360$^{\circ}$ view from a single frame.  Such a camera is ideal for doing visual SLAM.  However doing SLAM with a single camera has its own pitfalls.  Firstly the maps and trajectory for mono SLAM will be determined in some non metric scale.  When using stereo, one can determine exact 3D locations of landmarks based on the disparity and a known baseline.  However with a single camera a feature point could lie anywhere on a ray from the focal center to infinity.  Using the 5 point algorithm (Section \ref{subsec:5point}), 3D positions of points of 2D-2D correspondences between two image frames may be estimated, along with a transformation, however this 3D information is represented in some non metric scale.

\begin{figure}[h!]
  \centering
    \includegraphics[width=1.0\textwidth]{chapters/images/unwrapped}
    \caption{Omni camera image unwrapped to panoramic picture}
  \label{fig:unwrapped}
\end{figure}

The second main problem with mono SLAM is scale drift.  Once a pose between two initial images has been calculated, further images need to be registered to this same scale.  The p3p algorithm (Section \ref{subsec:p3p}) calculates a pose for 2D-3D correspondences, propagating the same scale for the new landmarks.  However even a very small error in the scale estimation will cause scale drift over many frames, just as the 3D pose will also drift over long trajectories.

Therefore in order to make a more robust, accurate SLAM system, it would make sense to combine these two types of cameras to exploit their complimentary properties.  For smaller robots requiring minimal navigation solutions this may not be suitable, however this solution is well suited for larger robotic platforms that require highly accurate navigation, for instance self driving cars, robot forklifts or farming robots.  Two cameras is clearly more expensive than one, however such a localization solution is still orders of magnitude cheaper than a high end laser localization systems.

%Talk about the pros and cons of both cameras.  In short 
%\begin{center}
 %\begin{tabular}{ | l | p{5.5cm} | p{5.5cm} | }
  %\hline
  %\bf Camera & \bf Pros & \bf Cons \\ \hline
  %omni 
  %& sees 360 degrees, \newline 
  %tracks points for longer \newline
  %orientation invariant place recognition
  %& non metric scale \newline 
  %scale drift \newline less robust pose estimation\\ \hline
  
  %stereo 
  %& 3D data \newline metric scale \newline no scale drift
  %& small fov \newline
  %more susceptible to occlusions \newline 
  %tracks features not as long \newline 
  %harder to get an even distribution of features \\ \hline
 %\end{tabular}
%\end{center}
%Therefore combine them to get the ultimate visual slam setup!

\section{Approach}

There are many ways in which stereo and omnidirectional cameras could be fused together.  This section lists some approaches and discusses the selected strategy.

\subsection{Augment Mono-SLAM with stereo}

A straightforward approach would be to use a SLAM algorithm designed for mono slam and address the scale issue with stereo.  Metric 3D points can be determined from stereo and matched to 2D points from the omnidirectional image.  All points and poses may then be initialized to metric scale.  At any point in time the the scale from the mono system can be compared with metric scale and corrected, given there is some overlap field of view between the two cameras and some feature matches.  Nevertheless, using this strategy the performance of the SLAM system would not be improved, it would simply be the same mono SLAM system with correct scale.

\subsection{Augment Stereo-SLAM with an Omni camera}

\subsubsection{Improve Visual Odometry}

A potential improvement to stereo tracking would be to initialize landmarks with stereo and continue to track them as they go out of the stereo camera's field of view with the omni camera.  Pose estimation could be performed with the p3p algorithm using 2D $\rightarrow$ 3D correspondences between omni camera features and 3D landmarks as initialized by stereo.

This is a valid approach, although the manner in which 3D landmarks are initialized would need to be carefully considered.  For a forward facing stereo camera, new landmarks would often occur with large depth values, and therefore the stereo camera could not triangulate them accurately.

\subsubsection{Omni camera for loop closure}

The idea here is to use the omni camera to find global loop closures where the stereo camera would fail due to no field of field overlap.  The omni camera can match frames regardless of rotation about the upward facing axis, due to the 360$^{\circ}$ view.  (Fig. \ref{fig:omni_loop_close}) This means that for a robot driving on a ground plane, it could recognize and even match frames invariant of the robots orientation.

\begin{figure}[h!]
  \centering
    \includegraphics[width=0.49\textwidth]{chapters/images/stereo_loop}
    \includegraphics[width=0.49\textwidth]{chapters/images/omni_loop} 
    \caption{Loop closure using a perspective (e.g. stereo) camera and omni camera.  The omni camera can find loop closures regardless of the cameras pose}
  \label{fig:omni_loop_close}
\end{figure}

\subsection{Tight integration of all cameras}

Another idea is to combine all camera images at the lowest level to enable a tight sensor integration.  A naive implementation of this would be to use a mono SLAM system and treat the images from extras cameras as extra frames.  This could be improved upon by considering the fixed geometry between cameras.  Alternatively, a generalized camera model, as described in \cite{pless_03}, could be used to combine all the cameras as one, and use a pose estimation method such as \cite{stewenius_05} with the generalized camera model.

\subsection{Selected Approaches}
\label{subsec:selected_approach}

When developing an online SLAM system, a very important factor to consider is visual odometry drift.  Even with high accuarcy tracking, there will always be some small error which will propagate and over time and cause the trajectory and map to deteriorate. It is likely that tracking accuracy and robustness can be improved by combining stereo and omni cameras in the visual odometry stage, however drift will still occur.

Therefore it is conceivable that the most significant improvement may be made by improving the instances and quality of loop closures to correct for drift.  As a result the omni camera for loop closure has been selected as the approach for this work.  However this approach is not so trivial, as the non metric scale issues still exists.  This exact problem will be addressed in this work.